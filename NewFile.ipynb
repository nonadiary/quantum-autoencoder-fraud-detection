{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d59a7d0",
   "metadata": {},
   "source": [
    "# Quantum Autoencoder: DIFE and LS-SWAP Implementation\n",
    "\n",
    "**Implementation of two new quantum autoencoder strategies for fraud detection:**\n",
    "\n",
    "1. **DIFE (Destructive Interference Fidelity Estimation)**: Ancilla-free QAE using compute/uncompute sequence\n",
    "2. **LS-SWAP (Latent Space SWAP Test)**: Resource-optimized SWAP test on latent space only\n",
    "\n",
    "**Based on**: Technical specification for advanced QAE strategies with reduced resource requirements\n",
    "\n",
    "---\n",
    "\n",
    "## Key Features:\n",
    "\n",
    "### DIFE Strategy:\n",
    "- **Ancilla-free**: No additional reference or control qubits needed\n",
    "- **Compute/Uncompute**: Forward pass followed by adjoint operation\n",
    "- **Destructive Interference**: Measures probability of returning to |0⟩ state\n",
    "- **8 qubits total** (same as enhanced_qvae data qubits)\n",
    "\n",
    "### LS-SWAP Strategy:\n",
    "- **Latent Space Focus**: SWAP test only on compressed representation\n",
    "- **Resource Efficient**: Fewer ancilla qubits than full SWAP test\n",
    "- **11 qubits total** (8 data + 2 reference + 1 control)\n",
    "- **Maintains SWAP test benefits** with reduced complexity\n",
    "\n",
    "**Goal**: Evaluate if these resource-optimized strategies can match or exceed enhanced_qvae performance while using fewer quantum resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cdf22195",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\envs\\my312\\Lib\\site-packages\\requests\\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully!\n",
      "PennyLane version: 0.41.1\n",
      "Ready for DIFE and LS-SWAP implementation!\n"
     ]
    }
   ],
   "source": [
    "# Core libraries for data processing and machine learning\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (confusion_matrix, accuracy_score, precision_score,\n",
    "                             recall_score, f1_score, roc_auc_score)\n",
    "from sklearn.decomposition import PCA\n",
    "import time\n",
    "\n",
    "# Quantum machine learning framework\n",
    "import pennylane as qml\n",
    "import pennylane.numpy as pnp\n",
    "\n",
    "print(\"Libraries imported successfully!\")\n",
    "print(f\"PennyLane version: {qml.__version__}\")\n",
    "print(\"Ready for DIFE and LS-SWAP implementation!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "afc405ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded: 946 samples, 30 features\n",
      "Fraud rate: 0.5000 (473 fraud cases)\n",
      "\n",
      "Training set: (756, 4)\n",
      "Test set: (190, 4)\n",
      "PCA explained variance ratio: [0.38421646 0.10954544 0.06067923 0.05752846]\n",
      "Total variance explained: 0.6120\n",
      "\n",
      "Training set: (756, 4)\n",
      "Test set: (190, 4)\n",
      "PCA explained variance ratio: [0.38421646 0.10954544 0.06067923 0.05752846]\n",
      "Total variance explained: 0.6120\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# Data Loading and Preprocessing Pipeline\n",
    "# ==========================================\n",
    "\n",
    "# Load preprocessed credit card fraud dataset\n",
    "df = pd.read_csv(\"preprocessed-creditcard.csv\")\n",
    "X = df.drop(\"Class\", axis=1).values  # Feature matrix\n",
    "y = df[\"Class\"].values                # Target labels (0: normal, 1: fraud)\n",
    "\n",
    "print(f\"Dataset loaded: {X.shape[0]} samples, {X.shape[1]} features\")\n",
    "print(f\"Fraud rate: {np.mean(y):.4f} ({np.sum(y)} fraud cases)\")\n",
    "\n",
    "# Stratified train-test split to maintain class distribution\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# Feature standardization using Z-score normalization\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test  = scaler.transform(X_test)\n",
    "\n",
    "# Dimensionality reduction using PCA to match quantum register size\n",
    "pca = PCA(n_components=4, random_state=42)\n",
    "X_train_4d = pca.fit_transform(X_train)\n",
    "X_test_4d  = pca.transform(X_test)\n",
    "\n",
    "print(f\"\\nTraining set: {X_train_4d.shape}\")\n",
    "print(f\"Test set: {X_test_4d.shape}\")\n",
    "print(f\"PCA explained variance ratio: {pca.explained_variance_ratio_}\")\n",
    "print(f\"Total variance explained: {np.sum(pca.explained_variance_ratio_):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ea845f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "QUANTUM AUTOENCODER - DIFE and LS-SWAP IMPLEMENTATION\n",
      "================================================================================\n",
      "DIFE Configuration:\n",
      "  - Total qubits: 8 (ancilla-free)\n",
      "  - Compute/Uncompute: True\n",
      "  - Data Re-uploading: True\n",
      "  - Alternate RY/RX: True\n",
      "\n",
      "LS-SWAP Configuration:\n",
      "  - Data qubits: 8\n",
      "  - Latent qubits: 2\n",
      "  - Total qubits: 11 (8 data + 2 ref + 1 control)\n",
      "  - Latent-only SWAP: True\n",
      "\n",
      "Shared Features:\n",
      "  - Parallel Embedding: 2x\n",
      "  - Variational Layers: 4\n",
      "\n",
      "Training Configuration: {'epochs_dife': 100, 'epochs_ls_swap': 100, 'batch_size': 16, 'learning_rate': 0.001}\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# Configuration for DIFE and LS-SWAP Strategies\n",
    "# ==========================================\n",
    "\n",
    "# SHARED ENHANCED qVAE FEATURES (from existing implementation)\n",
    "USE_DATA_REUPLOADING = True     # Embed data at each variational layer\n",
    "USE_PARALLEL_EMBEDDING = 2      # Replicate data across multiple qubits (2x = 8 data qubits)\n",
    "USE_ALTERNATE_EMBEDDING = True  # Alternate between RY and RX rotations\n",
    "\n",
    "# NEW STRATEGY SPECIFIC PARAMETERS\n",
    "# DIFE Configuration\n",
    "DIFE_USE_COMPUTE_UNCOMPUTE = True  # Enable compute/uncompute sequence\n",
    "\n",
    "# LS-SWAP Configuration  \n",
    "LS_SWAP_LATENT_QUBITS = 2        # Number of latent space qubits for SWAP test\n",
    "LS_SWAP_USE_LATENT_ONLY = True   # Restrict SWAP test to latent space\n",
    "\n",
    "# QUANTUM ARCHITECTURE PARAMETERS\n",
    "N_DATA_QUBITS = 4 * USE_PARALLEL_EMBEDDING  # 8 data qubits\n",
    "N_LATENT = LS_SWAP_LATENT_QUBITS             # 2 latent qubits\n",
    "L = 4  # Number of variational layers\n",
    "\n",
    "# TRAINING CONFIGURATION야\n",
    "TRAINING_CONFIG = {\n",
    "    'epochs_dife': 100,         # DIFE strategy\n",
    "    'epochs_ls_swap': 100,      # LS-SWAP strategy\n",
    "    'batch_size': 16,           # Batch size for both strategies\n",
    "    'learning_rate': 0.001      # Adam optimizer stepsize\n",
    "}\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"QUANTUM AUTOENCODER - DIFE and LS-SWAP IMPLEMENTATION\")\n",
    "print(\"=\"*80)\n",
    "print(f\"DIFE Configuration:\")\n",
    "print(f\"  - Total qubits: {N_DATA_QUBITS} (ancilla-free)\")\n",
    "print(f\"  - Compute/Uncompute: {DIFE_USE_COMPUTE_UNCOMPUTE}\")\n",
    "print(f\"  - Data Re-uploading: {USE_DATA_REUPLOADING}\")\n",
    "print(f\"  - Alternate RY/RX: {USE_ALTERNATE_EMBEDDING}\")\n",
    "print()\n",
    "print(f\"LS-SWAP Configuration:\")\n",
    "print(f\"  - Data qubits: {N_DATA_QUBITS}\")\n",
    "print(f\"  - Latent qubits: {N_LATENT}\")\n",
    "print(f\"  - Total qubits: {N_DATA_QUBITS + N_LATENT + 1} ({N_DATA_QUBITS} data + {N_LATENT} ref + 1 control)\")\n",
    "print(f\"  - Latent-only SWAP: {LS_SWAP_USE_LATENT_ONLY}\")\n",
    "print(f\"\\nShared Features:\")\n",
    "print(f\"  - Parallel Embedding: {USE_PARALLEL_EMBEDDING}x\")\n",
    "print(f\"  - Variational Layers: {L}\")\n",
    "print(f\"\\nTraining Configuration: {TRAINING_CONFIG}\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a136034c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shared quantum circuit functions defined successfully!\n",
      "  - enhanced_qvae_layer: Advanced embedding with re-uploading\n",
      "  - encoder_ansatz: Complete encoder for DIFE and LS-SWAP\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# Shared Quantum Circuit Functions\n",
    "# ==========================================\n",
    "\n",
    "def enhanced_qvae_layer(inputs, weights, layer_idx, n_layers, n_qubits, reupload=True, alternate_embedding=False):\n",
    "    \"\"\"\n",
    "    Enhanced qVAE layer with data re-uploading and advanced embedding.\n",
    "    \n",
    "    Based on the implementation from 'The role of data embedding in quantum autoencoders \n",
    "    for improved anomaly detection' paper.\n",
    "    \n",
    "    Args:\n",
    "        inputs: Input data features\n",
    "        weights: Trainable parameters for this layer\n",
    "        layer_idx: Current layer index\n",
    "        n_layers: Total number of layers\n",
    "        n_qubits: Number of data qubits\n",
    "        reupload: Whether to use data re-uploading\n",
    "        alternate_embedding: Whether to alternate between RY and RX\n",
    "    \"\"\"\n",
    "    # Data embedding (with re-uploading if enabled)\n",
    "    if not reupload or layer_idx == 0:  # Always embed on first layer\n",
    "        for i, feature in enumerate(inputs):\n",
    "            # Parallel embedding: replicate data across multiple qubits\n",
    "            for p in range(USE_PARALLEL_EMBEDDING):\n",
    "                qubit_idx = i * USE_PARALLEL_EMBEDDING + p\n",
    "                if qubit_idx < n_qubits:\n",
    "                    if alternate_embedding and (i + p) % 2 == 1:\n",
    "                        qml.RX(feature, wires=qubit_idx)\n",
    "                    else:\n",
    "                        qml.RY(feature, wires=qubit_idx)\n",
    "    \n",
    "    # Parameterized rotations for each qubit\n",
    "    for w in range(n_qubits):\n",
    "        qml.RY(weights[w, 0], wires=w)\n",
    "        qml.RZ(weights[w, 1], wires=w)\n",
    "    \n",
    "    # Entangling gates with periodic boundary\n",
    "    if n_qubits > 1:\n",
    "        for w in range(n_qubits):\n",
    "            control = w\n",
    "            target = (w + 1) % n_qubits\n",
    "            qml.CNOT(wires=[control, target])\n",
    "    \n",
    "    # Data re-uploading for intermediate layers\n",
    "    if reupload and layer_idx < n_layers - 1:\n",
    "        for i, feature in enumerate(inputs):\n",
    "            for p in range(USE_PARALLEL_EMBEDDING):\n",
    "                qubit_idx = i * USE_PARALLEL_EMBEDDING + p\n",
    "                if qubit_idx < n_qubits:\n",
    "                    if alternate_embedding and (i + p) % 2 == 1:\n",
    "                        qml.RX(feature, wires=qubit_idx)\n",
    "                    else:\n",
    "                        qml.RY(feature, wires=qubit_idx)\n",
    "\n",
    "def encoder_ansatz(x, weights, n_qubits):\n",
    "    \"\"\"\n",
    "    Complete encoder ansatz for use in both DIFE and LS-SWAP strategies.\n",
    "    This encapsulates the full enhanced qVAE encoding logic.\n",
    "    \n",
    "    Args:\n",
    "        x: Input features\n",
    "        weights: Trainable parameters\n",
    "        n_qubits: Number of data qubits\n",
    "    \"\"\"\n",
    "    # Apply enhanced qVAE layers with data re-uploading\n",
    "    for l in range(L):\n",
    "        enhanced_qvae_layer(\n",
    "            inputs=x,\n",
    "            weights=weights[l],\n",
    "            layer_idx=l,\n",
    "            n_layers=L,\n",
    "            n_qubits=n_qubits,\n",
    "            reupload=USE_DATA_REUPLOADING,\n",
    "            alternate_embedding=USE_ALTERNATE_EMBEDDING\n",
    "        )\n",
    "\n",
    "print(\"Shared quantum circuit functions defined successfully!\")\n",
    "print(\"  - enhanced_qvae_layer: Advanced embedding with re-uploading\")\n",
    "print(\"  - encoder_ansatz: Complete encoder for DIFE and LS-SWAP\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f803c931",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DIFE Strategy Implementation Complete!\n",
      "  - Ancilla-free: Uses only 8 data qubits\n",
      "  - Compute/Uncompute: Forward + adjoint sequence\n",
      "  - Measurement: Projector onto |0⟩^⊗8 state\n",
      "  - Interference: Perfect reconstruction → high probability\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# DIFE Strategy Implementation\n",
    "# ==========================================\n",
    "\n",
    "def dife_circuit(x, weights, n_qubits):\n",
    "    \"\"\"\n",
    "    DIFE (Destructive Interference Fidelity Estimation) circuit implementation.\n",
    "    \n",
    "    This ancilla-free approach uses a compute/uncompute sequence to estimate \n",
    "    reconstruction fidelity through destructive interference measurement.\n",
    "    \n",
    "    Circuit sequence:\n",
    "    1. Start with |0⟩^⊗n state\n",
    "    2. Apply encoder U_enc(x, θ) - Forward pass (compute)\n",
    "    3. Apply U_enc†(x, θ) - Backward pass (uncompute)\n",
    "    4. Measure probability of returning to |0⟩^⊗n\n",
    "    \n",
    "    Perfect reconstruction → constructive interference → high probability\n",
    "    Poor reconstruction → destructive interference → low probability\n",
    "    \n",
    "    Args:\n",
    "        x: Input data features\n",
    "        weights: Trainable parameters\n",
    "        n_qubits: Number of data qubits (8)\n",
    "    \n",
    "    Returns:\n",
    "        Expectation value of projector onto |0⟩^⊗n state\n",
    "    \"\"\"\n",
    "    # Step 1: Forward pass (compute) - Apply encoder\n",
    "    encoder_ansatz(x, weights, n_qubits)\n",
    "    \n",
    "    # Step 2: Backward pass (uncompute) - Apply adjoint of encoder\n",
    "    qml.adjoint(encoder_ansatz)(x, weights, n_qubits)\n",
    "    \n",
    "    # Step 3: Measure probability of returning to |0⟩^⊗n state\n",
    "    # Create zero state projector for all qubits\n",
    "    zero_state = [0] * n_qubits\n",
    "    return qml.expval(qml.Projector(zero_state, wires=range(n_qubits)))\n",
    "\n",
    "print(\"DIFE Strategy Implementation Complete!\")\n",
    "print(\"  - Ancilla-free: Uses only 8 data qubits\")\n",
    "print(\"  - Compute/Uncompute: Forward + adjoint sequence\")  \n",
    "print(\"  - Measurement: Projector onto |0⟩^⊗8 state\")\n",
    "print(\"  - Interference: Perfect reconstruction → high probability\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ff9f44dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LS-SWAP Strategy Implementation Complete!\n",
      "  - Resource-efficient: 11 qubits vs 13 for full SWAP test\n",
      "  - Latent focus: SWAP test on compressed representation only\n",
      "  - Wire layout: Latent (0,1), Data (2-7), Reference (8,9), Control (10)\n",
      "  - Measurement: PauliZ expectation on control qubit\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# LS-SWAP Strategy Implementation \n",
    "# ==========================================\n",
    "\n",
    "def latent_space_swap_test(n_data_qubits, n_latent, total_qubits):\n",
    "    \"\"\"\n",
    "    Implement SWAP test restricted to latent space qubits only.\n",
    "    \n",
    "    This resource-optimized SWAP test operates on the assumption that \n",
    "    the fidelity of the compressed latent state is a sufficient proxy \n",
    "    for the fidelity of the entire system.\n",
    "    \n",
    "    Qubit layout:\n",
    "    - Latent qubits: wires 0 to n_latent-1 (first 2 data qubits)\n",
    "    - Reference qubits: wires n_data_qubits to n_data_qubits+n_latent-1\n",
    "    - Control qubit: wire total_qubits-1 (last qubit)\n",
    "    \n",
    "    Args:\n",
    "        n_data_qubits: Number of data qubits (8)\n",
    "        n_latent: Number of latent space qubits (2)\n",
    "        total_qubits: Total qubits in circuit (11)\n",
    "    \n",
    "    Returns:\n",
    "        Expectation value of PauliZ on control qubit\n",
    "    \"\"\"\n",
    "    control_qubit = total_qubits - 1  # Last qubit as control\n",
    "    \n",
    "    # Apply Hadamard to control qubit\n",
    "    qml.Hadamard(wires=control_qubit)\n",
    "    \n",
    "    # Controlled SWAP operations between latent and reference qubits\n",
    "    for i in range(n_latent):\n",
    "        latent_qubit = i                           # Latent space qubit (0, 1)\n",
    "        reference_qubit = n_data_qubits + i        # Reference qubit (8, 9)\n",
    "        qml.CSWAP(wires=[control_qubit, latent_qubit, reference_qubit])\n",
    "    \n",
    "    # Final Hadamard on control qubit  \n",
    "    qml.Hadamard(wires=control_qubit)\n",
    "    \n",
    "    # Measure control qubit\n",
    "    return qml.expval(qml.PauliZ(control_qubit))\n",
    "\n",
    "def ls_swap_circuit(x, weights, n_qubits, total_qubits):\n",
    "    \"\"\"\n",
    "    LS-SWAP (Latent Space SWAP Test) circuit implementation.\n",
    "    \n",
    "    This strategy combines the enhanced qVAE encoder with a resource-efficient\n",
    "    SWAP test that operates only on the latent space representation.\n",
    "    \n",
    "    Circuit sequence:\n",
    "    1. Apply enhanced qVAE encoder to data qubits\n",
    "    2. Perform SWAP test between latent qubits (0,1) and reference qubits (8,9)\n",
    "    3. Measure control qubit for fidelity estimation\n",
    "    \n",
    "    Args:\n",
    "        x: Input data features  \n",
    "        weights: Trainable parameters\n",
    "        n_qubits: Number of data qubits (8)\n",
    "        total_qubits: Total qubits including ancilla (11)\n",
    "        \n",
    "    Returns:\n",
    "        SWAP test expectation value for fidelity estimation\n",
    "    \"\"\"\n",
    "    # Apply enhanced qVAE encoder to data qubits\n",
    "    encoder_ansatz(x, weights, n_qubits)\n",
    "    \n",
    "    # Perform latent space SWAP test\n",
    "    return latent_space_swap_test(n_qubits, N_LATENT, total_qubits)\n",
    "\n",
    "print(\"LS-SWAP Strategy Implementation Complete!\")\n",
    "print(\"  - Resource-efficient: 11 qubits vs 13 for full SWAP test\")\n",
    "print(\"  - Latent focus: SWAP test on compressed representation only\")\n",
    "print(\"  - Wire layout: Latent (0,1), Data (2-7), Reference (8,9), Control (10)\")\n",
    "print(\"  - Measurement: PauliZ expectation on control qubit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "04ea36ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training functions defined successfully!\n",
      "  - train_dife_strategy: Ancilla-free compute/uncompute training\n",
      "  - train_ls_swap_strategy: Latent space SWAP test training\n",
      "  - compute_batch_cost: Strategy-specific loss computation\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# Training Functions\n",
    "# ==========================================\n",
    "\n",
    "def compute_batch_cost(samples, circuit, weights, strategy_name):\n",
    "    \"\"\"\n",
    "    Compute batch cost for different strategies with appropriate loss functions.\n",
    "    \n",
    "    Args:\n",
    "        samples: Batch data samples\n",
    "        circuit: Quantum circuit function\n",
    "        weights: Trainable parameters\n",
    "        strategy_name: 'dife' or 'ls_swap' for strategy-specific handling\n",
    "        \n",
    "    Returns:\n",
    "        linear_loss: Linear loss (1 - fidelity)\n",
    "        squared_loss: Squared loss (1 - fidelity)^2\n",
    "    \"\"\"\n",
    "    linear_errors = []\n",
    "    squared_errors = []\n",
    "    \n",
    "    for sample in samples:\n",
    "        features = pnp.array(sample, requires_grad=False)\n",
    "        expval = circuit(features, weights)\n",
    "        \n",
    "        # Strategy-specific fidelity calculation\n",
    "        if strategy_name == 'dife':\n",
    "            # DIFE: expval is already the probability of returning to |0⟩^⊗n\n",
    "            fidelity = expval\n",
    "        elif strategy_name == 'ls_swap':\n",
    "            # LS-SWAP: Convert SWAP test expval to fidelity\n",
    "            fidelity = (expval + 1.0) / 2.0\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown strategy: {strategy_name}\")\n",
    "        \n",
    "        # Ensure fidelity is in valid range [0, 1]\n",
    "        fidelity = pnp.clip(fidelity, 0.0, 1.0)\n",
    "        \n",
    "        # Linear and squared loss calculations\n",
    "        linear_error = 1.0 - fidelity\n",
    "        squared_error = linear_error ** 2\n",
    "        \n",
    "        linear_errors.append(linear_error)\n",
    "        squared_errors.append(squared_error)\n",
    "    \n",
    "    linear_loss = pnp.mean(pnp.stack(linear_errors))\n",
    "    squared_loss = pnp.mean(pnp.stack(squared_errors))\n",
    "    \n",
    "    return linear_loss, squared_loss\n",
    "\n",
    "def train_dife_strategy():\n",
    "    \"\"\"\n",
    "    Train the DIFE (Destructive Interference Fidelity Estimation) strategy.\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"TRAINING: DIFE STRATEGY\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Create quantum device and circuit\n",
    "    n_qubits = N_DATA_QUBITS  # 8 data qubits\n",
    "    dev = qml.device(\"lightning.qubit\", wires=n_qubits)\n",
    "    \n",
    "    @qml.qnode(dev)\n",
    "    def dife_qnode(x, weights):\n",
    "        return dife_circuit(x, weights, n_qubits)\n",
    "    \n",
    "    # Initialize weights (2 parameters per qubit per layer for enhanced qVAE)\n",
    "    weights = pnp.random.uniform(-pnp.pi, pnp.pi, (L, n_qubits, 2), requires_grad=True)\n",
    "    \n",
    "    # Training configuration\n",
    "    epochs = TRAINING_CONFIG[\"epochs_dife\"]\n",
    "    batch_size = TRAINING_CONFIG[\"batch_size\"]\n",
    "    optimizer = qml.AdamOptimizer(stepsize=TRAINING_CONFIG[\"learning_rate\"])\n",
    "    \n",
    "    print(f\"Configuration:\")\n",
    "    print(f\"  - Qubits: {n_qubits} (ancilla-free)\")\n",
    "    print(f\"  - Parameters: {np.prod(weights.shape)}\")\n",
    "    print(f\"  - Epochs: {epochs}, Batch size: {batch_size}\")\n",
    "    print(f\"  - Strategy: Compute/Uncompute with |0⟩^⊗n measurement\")\n",
    "    \n",
    "    # Training loop\n",
    "    training_losses = []\n",
    "    linear_losses = []\n",
    "    squared_losses = []\n",
    "    start_time = time.time()\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        epoch_linear_losses = []\n",
    "        epoch_squared_losses = []\n",
    "        \n",
    "        for batch_start in range(0, len(X_train_4d), batch_size):\n",
    "            batch_end = min(batch_start + batch_size, len(X_train_4d))\n",
    "            X_batch = X_train_4d[batch_start:batch_end]\n",
    "            \n",
    "            # Batch cost function wrapper\n",
    "            def batch_cost_wrapper(w):\n",
    "                linear_loss, squared_loss = compute_batch_cost(X_batch, dife_qnode, w, 'dife')\n",
    "                # Use linear loss as optimization target for DIFE\n",
    "                return linear_loss\n",
    "            \n",
    "            # Optimize weights\n",
    "            weights = optimizer.step(batch_cost_wrapper, weights)\n",
    "            \n",
    "            # Record losses\n",
    "            linear_loss, squared_loss = compute_batch_cost(X_batch, dife_qnode, weights, 'dife')\n",
    "            epoch_linear_losses.append(float(linear_loss))\n",
    "            epoch_squared_losses.append(float(squared_loss))\n",
    "        \n",
    "        # Epoch summary\n",
    "        avg_linear_loss = np.mean(epoch_linear_losses)\n",
    "        avg_squared_loss = np.mean(epoch_squared_losses)\n",
    "        linear_losses.append(avg_linear_loss)\n",
    "        squared_losses.append(avg_squared_loss)\n",
    "        training_losses.append(avg_linear_loss)  # DIFE uses linear loss\n",
    "        \n",
    "        if (epoch + 1) % 10 == 0 or epoch == epochs - 1:\n",
    "            print(f\"  Epoch {epoch+1:3d}/{epochs} - Linear Loss: {avg_linear_loss:.6f}, Squared Loss: {avg_squared_loss:.6f}\")\n",
    "    \n",
    "    training_time = time.time() - start_time\n",
    "    print(f\"Training completed in {training_time:.1f}s - Final loss: {training_losses[-1]:.6f}\")\n",
    "    \n",
    "    return {\n",
    "        \"strategy\": \"dife\",\n",
    "        \"weights\": weights,\n",
    "        \"losses\": training_losses,\n",
    "        \"linear_losses\": linear_losses,\n",
    "        \"squared_losses\": squared_losses,\n",
    "        \"circuit\": dife_qnode,\n",
    "        \"n_qubits\": n_qubits,\n",
    "        \"total_qubits\": n_qubits,  # Same for ancilla-free DIFE\n",
    "        \"training_time\": training_time,\n",
    "        \"final_loss\": training_losses[-1],\n",
    "    }\n",
    "\n",
    "def train_ls_swap_strategy():\n",
    "    \"\"\"\n",
    "    Train the LS-SWAP (Latent Space SWAP Test) strategy.\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"TRAINING: LS-SWAP STRATEGY\")  \n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Create quantum device and circuit\n",
    "    n_qubits = N_DATA_QUBITS  # 8 data qubits\n",
    "    total_qubits = n_qubits + N_LATENT + 1  # 11 total qubits\n",
    "    dev = qml.device(\"lightning.qubit\", wires=total_qubits)\n",
    "    \n",
    "    @qml.qnode(dev)\n",
    "    def ls_swap_qnode(x, weights):\n",
    "        return ls_swap_circuit(x, weights, n_qubits, total_qubits)\n",
    "    \n",
    "    # Initialize weights (2 parameters per qubit per layer)\n",
    "    weights = pnp.random.uniform(-pnp.pi, pnp.pi, (L, n_qubits, 2), requires_grad=True)\n",
    "    \n",
    "    # Training configuration  \n",
    "    epochs = TRAINING_CONFIG[\"epochs_ls_swap\"]\n",
    "    batch_size = TRAINING_CONFIG[\"batch_size\"]\n",
    "    optimizer = qml.AdamOptimizer(stepsize=TRAINING_CONFIG[\"learning_rate\"])\n",
    "    \n",
    "    print(f\"Configuration:\")\n",
    "    print(f\"  - Data Qubits: {n_qubits}\")\n",
    "    print(f\"  - Latent Qubits: {N_LATENT}\")\n",
    "    print(f\"  - Total Qubits: {total_qubits}\")\n",
    "    print(f\"  - Parameters: {np.prod(weights.shape)}\")\n",
    "    print(f\"  - Epochs: {epochs}, Batch size: {batch_size}\")\n",
    "    print(f\"  - Strategy: Latent Space SWAP Test\")\n",
    "    \n",
    "    # Training loop\n",
    "    training_losses = []\n",
    "    linear_losses = []\n",
    "    squared_losses = []  \n",
    "    start_time = time.time()\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        epoch_linear_losses = []\n",
    "        epoch_squared_losses = []\n",
    "        \n",
    "        for batch_start in range(0, len(X_train_4d), batch_size):\n",
    "            batch_end = min(batch_start + batch_size, len(X_train_4d))\n",
    "            X_batch = X_train_4d[batch_start:batch_end]\n",
    "            \n",
    "            # Batch cost function wrapper\n",
    "            def batch_cost_wrapper(w):\n",
    "                linear_loss, squared_loss = compute_batch_cost(X_batch, ls_swap_qnode, w, 'ls_swap')\n",
    "                # Use linear loss as optimization target for LS-SWAP\n",
    "                return linear_loss\n",
    "            \n",
    "            # Optimize weights\n",
    "            weights = optimizer.step(batch_cost_wrapper, weights)\n",
    "            \n",
    "            # Record losses\n",
    "            linear_loss, squared_loss = compute_batch_cost(X_batch, ls_swap_qnode, weights, 'ls_swap')\n",
    "            epoch_linear_losses.append(float(linear_loss))\n",
    "            epoch_squared_losses.append(float(squared_loss))\n",
    "        \n",
    "        # Epoch summary\n",
    "        avg_linear_loss = np.mean(epoch_linear_losses)\n",
    "        avg_squared_loss = np.mean(epoch_squared_losses)\n",
    "        linear_losses.append(avg_linear_loss)\n",
    "        squared_losses.append(avg_squared_loss)\n",
    "        training_losses.append(avg_linear_loss)  # LS-SWAP uses linear loss\n",
    "        \n",
    "        if (epoch + 1) % 10 == 0 or epoch == epochs - 1:\n",
    "            print(f\"  Epoch {epoch+1:3d}/{epochs} - Linear Loss: {avg_linear_loss:.6f}, Squared Loss: {avg_squared_loss:.6f}\")\n",
    "    \n",
    "    training_time = time.time() - start_time\n",
    "    print(f\"Training completed in {training_time:.1f}s - Final loss: {training_losses[-1]:.6f}\")\n",
    "    \n",
    "    return {\n",
    "        \"strategy\": \"ls_swap\",\n",
    "        \"weights\": weights,\n",
    "        \"losses\": training_losses,\n",
    "        \"linear_losses\": linear_losses,\n",
    "        \"squared_losses\": squared_losses, \n",
    "        \"circuit\": ls_swap_qnode,\n",
    "        \"n_qubits\": n_qubits,\n",
    "        \"total_qubits\": total_qubits,\n",
    "        \"training_time\": training_time,\n",
    "        \"final_loss\": training_losses[-1],\n",
    "    }\n",
    "\n",
    "print(\"Training functions defined successfully!\")\n",
    "print(\"  - train_dife_strategy: Ancilla-free compute/uncompute training\")\n",
    "print(\"  - train_ls_swap_strategy: Latent space SWAP test training\")\n",
    "print(\"  - compute_batch_cost: Strategy-specific loss computation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f2c93bf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STARTING TRAINING OF DIFE AND LS-SWAP STRATEGIES\n",
      "================================================================================\n",
      "\n",
      "============================================================\n",
      "TRAINING: DIFE STRATEGY\n",
      "============================================================\n",
      "Configuration:\n",
      "  - Qubits: 8 (ancilla-free)\n",
      "  - Parameters: 64\n",
      "  - Epochs: 100, Batch size: 16\n",
      "  - Strategy: Compute/Uncompute with |0⟩^⊗n measurement\n",
      "Configuration:\n",
      "  - Qubits: 8 (ancilla-free)\n",
      "  - Parameters: 64\n",
      "  - Epochs: 100, Batch size: 16\n",
      "  - Strategy: Compute/Uncompute with |0⟩^⊗n measurement\n",
      "  Epoch  10/100 - Linear Loss: 0.000000, Squared Loss: 0.000000\n",
      "  Epoch  10/100 - Linear Loss: 0.000000, Squared Loss: 0.000000\n",
      "  Epoch  20/100 - Linear Loss: 0.000000, Squared Loss: 0.000000\n",
      "  Epoch  20/100 - Linear Loss: 0.000000, Squared Loss: 0.000000\n",
      "  Epoch  30/100 - Linear Loss: 0.000000, Squared Loss: 0.000000\n",
      "  Epoch  30/100 - Linear Loss: 0.000000, Squared Loss: 0.000000\n",
      "  Epoch  40/100 - Linear Loss: 0.000000, Squared Loss: 0.000000\n",
      "  Epoch  40/100 - Linear Loss: 0.000000, Squared Loss: 0.000000\n",
      "  Epoch  50/100 - Linear Loss: 0.000000, Squared Loss: 0.000000\n",
      "  Epoch  50/100 - Linear Loss: 0.000000, Squared Loss: 0.000000\n",
      "  Epoch  60/100 - Linear Loss: 0.000000, Squared Loss: 0.000000\n",
      "  Epoch  60/100 - Linear Loss: 0.000000, Squared Loss: 0.000000\n",
      "  Epoch  70/100 - Linear Loss: 0.000000, Squared Loss: 0.000000\n",
      "  Epoch  70/100 - Linear Loss: 0.000000, Squared Loss: 0.000000\n",
      "  Epoch  80/100 - Linear Loss: 0.000000, Squared Loss: 0.000000\n",
      "  Epoch  80/100 - Linear Loss: 0.000000, Squared Loss: 0.000000\n",
      "  Epoch  90/100 - Linear Loss: 0.000000, Squared Loss: 0.000000\n",
      "  Epoch  90/100 - Linear Loss: 0.000000, Squared Loss: 0.000000\n",
      "  Epoch 100/100 - Linear Loss: 0.000000, Squared Loss: 0.000000\n",
      "Training completed in 11154.6s - Final loss: 0.000000\n",
      "✓ DIFE strategy completed successfully\n",
      "\n",
      "============================================================\n",
      "TRAINING: LS-SWAP STRATEGY\n",
      "============================================================\n",
      "Configuration:\n",
      "  - Data Qubits: 8\n",
      "  - Latent Qubits: 2\n",
      "  - Total Qubits: 11\n",
      "  - Parameters: 64\n",
      "  - Epochs: 100, Batch size: 16\n",
      "  - Strategy: Latent Space SWAP Test\n",
      "  Epoch 100/100 - Linear Loss: 0.000000, Squared Loss: 0.000000\n",
      "Training completed in 11154.6s - Final loss: 0.000000\n",
      "✓ DIFE strategy completed successfully\n",
      "\n",
      "============================================================\n",
      "TRAINING: LS-SWAP STRATEGY\n",
      "============================================================\n",
      "Configuration:\n",
      "  - Data Qubits: 8\n",
      "  - Latent Qubits: 2\n",
      "  - Total Qubits: 11\n",
      "  - Parameters: 64\n",
      "  - Epochs: 100, Batch size: 16\n",
      "  - Strategy: Latent Space SWAP Test\n",
      "  Epoch  10/100 - Linear Loss: 0.360196, Squared Loss: 0.130064\n",
      "  Epoch  10/100 - Linear Loss: 0.360196, Squared Loss: 0.130064\n",
      "  Epoch  20/100 - Linear Loss: 0.344901, Squared Loss: 0.120200\n",
      "  Epoch  20/100 - Linear Loss: 0.344901, Squared Loss: 0.120200\n",
      "  Epoch  30/100 - Linear Loss: 0.323680, Squared Loss: 0.108637\n",
      "  Epoch  30/100 - Linear Loss: 0.323680, Squared Loss: 0.108637\n",
      "  Epoch  40/100 - Linear Loss: 0.303921, Squared Loss: 0.100535\n",
      "  Epoch  40/100 - Linear Loss: 0.303921, Squared Loss: 0.100535\n",
      "  Epoch  50/100 - Linear Loss: 0.297401, Squared Loss: 0.098142\n",
      "  Epoch  50/100 - Linear Loss: 0.297401, Squared Loss: 0.098142\n",
      "  Epoch  60/100 - Linear Loss: 0.294515, Squared Loss: 0.096836\n",
      "  Epoch  60/100 - Linear Loss: 0.294515, Squared Loss: 0.096836\n",
      "  Epoch  70/100 - Linear Loss: 0.291150, Squared Loss: 0.095417\n",
      "  Epoch  70/100 - Linear Loss: 0.291150, Squared Loss: 0.095417\n",
      "  Epoch  80/100 - Linear Loss: 0.285188, Squared Loss: 0.092984\n",
      "  Epoch  80/100 - Linear Loss: 0.285188, Squared Loss: 0.092984\n",
      "  Epoch  90/100 - Linear Loss: 0.278357, Squared Loss: 0.090242\n",
      "  Epoch  90/100 - Linear Loss: 0.278357, Squared Loss: 0.090242\n",
      "  Epoch 100/100 - Linear Loss: 0.276293, Squared Loss: 0.089517\n",
      "Training completed in 6656.7s - Final loss: 0.276293\n",
      "✓ LS-SWAP strategy completed successfully\n",
      "\n",
      "================================================================================\n",
      "ALL TRAINING COMPLETED IN 17812.5s\n",
      "================================================================================\n",
      "\n",
      "TRAINING SUMMARY:\n",
      "Strategy     Status     Final Loss   Time (s)   Qubits  \n",
      "------------------------------------------------------------\n",
      "dife         SUCCESS    0.000000     11154.6    8       \n",
      "ls_swap      SUCCESS    0.276293     6656.7     11      \n",
      "\n",
      "Strategy Details:\n",
      "  DIFE: Ancilla-free compute/uncompute with |0⟩^⊗8 measurement\n",
      "  LS-SWAP: Latent space SWAP test (qubits 0,1 ↔ 8,9)\n",
      "\n",
      "Ready for evaluation and comparison!\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# Execute Training for Both Strategies\n",
    "# ==========================================\n",
    "\n",
    "print(\"STARTING TRAINING OF DIFE AND LS-SWAP STRATEGIES\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "results = {}\n",
    "total_start_time = time.time()\n",
    "\n",
    "# Train DIFE strategy\n",
    "try:\n",
    "    dife_result = train_dife_strategy()\n",
    "    results['dife'] = dife_result\n",
    "    print(f\"✓ DIFE strategy completed successfully\")\n",
    "except Exception as e:\n",
    "    print(f\"✗ DIFE strategy failed: {str(e)}\")\n",
    "    results['dife'] = {'error': str(e)}\n",
    "\n",
    "# Train LS-SWAP strategy  \n",
    "try:\n",
    "    ls_swap_result = train_ls_swap_strategy()\n",
    "    results['ls_swap'] = ls_swap_result\n",
    "    print(f\"✓ LS-SWAP strategy completed successfully\")\n",
    "except Exception as e:\n",
    "    print(f\"✗ LS-SWAP strategy failed: {str(e)}\")\n",
    "    results['ls_swap'] = {'error': str(e)}\n",
    "\n",
    "total_time = time.time() - total_start_time\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"ALL TRAINING COMPLETED IN {total_time:.1f}s\")\n",
    "print(f\"{'='*80}\")\n",
    "\n",
    "# Training summary\n",
    "print(f\"\\nTRAINING SUMMARY:\")\n",
    "print(f\"{'Strategy':<12} {'Status':<10} {'Final Loss':<12} {'Time (s)':<10} {'Qubits':<8}\")\n",
    "print(f\"{'-'*60}\")\n",
    "for strategy in ['dife', 'ls_swap']:\n",
    "    if strategy in results:\n",
    "        if 'error' in results[strategy]:\n",
    "            print(f\"{strategy:<12} {'FAILED':<10} {'N/A':<12} {'N/A':<10} {'N/A':<8}\")\n",
    "        else:\n",
    "            result = results[strategy]\n",
    "            print(f\"{strategy:<12} {'SUCCESS':<10} {result['final_loss']:<12.6f} {result['training_time']:<10.1f} {result['total_qubits']:<8d}\")\n",
    "\n",
    "print(f\"\\nStrategy Details:\")\n",
    "print(f\"  DIFE: Ancilla-free compute/uncompute with |0⟩^⊗8 measurement\")\n",
    "print(f\"  LS-SWAP: Latent space SWAP test (qubits 0,1 ↔ 8,9)\")\n",
    "print(f\"\\nReady for evaluation and comparison!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bf27da6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation functions defined successfully!\n",
      "  - compute_metrics: Comprehensive classification metrics including G-Mean\n",
      "  - evaluate_strategy: Strategy-specific fidelity computation and evaluation\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# Evaluation Functions\n",
    "# ==========================================\n",
    "\n",
    "def compute_metrics(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Compute comprehensive evaluation metrics for binary classification.\n",
    "    \n",
    "    Includes standard metrics plus G-Mean which is particularly important\n",
    "    for imbalanced datasets as it balances sensitivity and specificity.\n",
    "    \"\"\"\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred, labels=[0,1]).ravel()\n",
    "    \n",
    "    # Standard classification metrics\n",
    "    acc  = accuracy_score(y_true, y_pred)\n",
    "    prec = precision_score(y_true, y_pred, zero_division=0)\n",
    "    rec  = recall_score(y_true, y_pred, zero_division=0)  # Sensitivity\n",
    "    f1   = f1_score(y_true, y_pred, zero_division=0)\n",
    "    \n",
    "    # Specificity (True Negative Rate)\n",
    "    spec = tn / (tn + fp) if (tn + fp) else 0.\n",
    "    \n",
    "    # Geometric Mean of Sensitivity and Specificity\n",
    "    # Balanced metric for imbalanced datasets\n",
    "    gmean = (rec * spec) ** 0.5\n",
    "    \n",
    "    return dict(TN=tn, FP=fp, FN=fn, TP=tp,\n",
    "                Accuracy=acc, Precision=prec,\n",
    "                Recall=rec, F1=f1, Specificity=spec, Gmean=gmean)\n",
    "\n",
    "def evaluate_strategy(strategy, result_data, X_test, y_test):\n",
    "    \"\"\"\n",
    "    Evaluate a single strategy on test data.\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"EVALUATING: {strategy.upper()} STRATEGY\")\n",
    "    print(f\"{'='*70}\")\n",
    "    \n",
    "    if 'error' in result_data:\n",
    "        print(f\"Strategy failed during training: {result_data['error']}\")\n",
    "        return None\n",
    "    \n",
    "    # Extract trained parameters\n",
    "    weights = result_data['weights']\n",
    "    circuit = result_data['circuit']\n",
    "    \n",
    "    print(f\"Computing reconstruction fidelities for {len(X_test)} test samples...\")\n",
    "    \n",
    "    # Compute fidelities\n",
    "    fidelities = []\n",
    "    for i, x in enumerate(X_test):\n",
    "        if i % 200 == 0:\n",
    "            print(f\"  Processed {i}/{len(X_test)} samples\")\n",
    "        \n",
    "        features = pnp.array(x, requires_grad=False)\n",
    "        \n",
    "        try:\n",
    "            # Use the trained circuit for this strategy\n",
    "            expval = circuit(features, weights)\n",
    "            \n",
    "            # Strategy-specific fidelity calculation\n",
    "            if strategy == \"dife\":\n",
    "                # DIFE: expval is already the probability/fidelity\n",
    "                fidelity = float(expval)\n",
    "            elif strategy == \"ls_swap\":\n",
    "                # LS-SWAP: Convert SWAP test expval to fidelity\n",
    "                fidelity = float((expval + 1.0) / 2.0)\n",
    "            else:\n",
    "                fidelity = 0.5  # Default for unknown strategy\n",
    "            \n",
    "            # Ensure fidelity is in valid range\n",
    "            fidelity = np.clip(fidelity, 0.0, 1.0)\n",
    "            fidelities.append(fidelity)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"    Error processing sample {i}: {e}\")\n",
    "            fidelities.append(0.5)  # Default fidelity for failed samples\n",
    "    \n",
    "    fidelities = np.array(fidelities)\n",
    "    \n",
    "    print(f\"\\nFidelity statistics:\")\n",
    "    print(f\"  Mean: {np.mean(fidelities):.4f}\")\n",
    "    print(f\"  Std:  {np.std(fidelities):.4f}\")\n",
    "    print(f\"  Min:  {np.min(fidelities):.4f}\")\n",
    "    print(f\"  Max:  {np.max(fidelities):.4f}\")\n",
    "    \n",
    "    # Threshold optimization\n",
    "    thresholds = [0.3, 0.4, 0.5, 0.6, 0.7, 0.8]\n",
    "    \n",
    "    best_gmean = 0\n",
    "    best_threshold = 0.5\n",
    "    best_metrics = {}\n",
    "    threshold_results = []\n",
    "    \n",
    "    print(f\"\\nThreshold optimization:\")\n",
    "    for T in thresholds:\n",
    "        # Classification rule: Low fidelity (fidelity < T) indicates fraud\n",
    "        y_pred = (fidelities < T).astype(int)\n",
    "        m = compute_metrics(y_test, y_pred)\n",
    "        \n",
    "        threshold_results.append({\n",
    "            'threshold': T,\n",
    "            'metrics': m\n",
    "        })\n",
    "        \n",
    "        print(f\"  T={T:.1f}: Acc={m['Accuracy']:.3f} Prec={m['Precision']:.3f} Rec={m['Recall']:.3f} F1={m['F1']:.3f} G-Mean={m['Gmean']:.3f}\")\n",
    "        \n",
    "        # Track best performance by G-Mean\n",
    "        if m['Gmean'] > best_gmean:\n",
    "            best_gmean = m['Gmean']\n",
    "            best_threshold = T\n",
    "            best_metrics = m\n",
    "    \n",
    "    # Calculate AUC-ROC\n",
    "    try:\n",
    "        auc = roc_auc_score(y_test, 1 - fidelities)  # 1-fidelity for anomaly score\n",
    "    except:\n",
    "        auc = 0.5\n",
    "    \n",
    "    # Ensure best_metrics has all required keys with default values\n",
    "    if not best_metrics:\n",
    "        best_metrics = {\n",
    "            'TN': 0, 'FP': 0, 'FN': 0, 'TP': 0,\n",
    "            'Accuracy': 0.0, 'Precision': 0.0,\n",
    "            'Recall': 0.0, 'F1': 0.0, 'Specificity': 0.0, 'Gmean': 0.0\n",
    "        }\n",
    "    \n",
    "    print(f\"\\nRESULTS SUMMARY:\")\n",
    "    print(f\"  AUC-ROC Score: {auc:.4f}\")\n",
    "    print(f\"  Best Threshold: {best_threshold} (G-Mean: {best_gmean:.3f})\")\n",
    "    print(f\"  Best Performance: Acc={best_metrics.get('Accuracy', 0):.3f}, \"\n",
    "          f\"Prec={best_metrics.get('Precision', 0):.3f}, \"\n",
    "          f\"Rec={best_metrics.get('Recall', 0):.3f}, \"\n",
    "          f\"F1={best_metrics.get('F1', 0):.3f}\")\n",
    "    \n",
    "    return {\n",
    "        'strategy': strategy,\n",
    "        'fidelities': fidelities,\n",
    "        'auc_roc': auc,\n",
    "        'best_threshold': best_threshold,\n",
    "        'best_gmean': best_gmean,\n",
    "        'best_metrics': best_metrics,\n",
    "        'threshold_results': threshold_results,\n",
    "        'training_time': result_data['training_time'],\n",
    "        'final_loss': result_data['final_loss'],\n",
    "        'n_qubits': result_data['n_qubits'],\n",
    "        'total_qubits': result_data['total_qubits']\n",
    "    }\n",
    "\n",
    "print(\"Evaluation functions defined successfully!\")\n",
    "print(\"  - compute_metrics: Comprehensive classification metrics including G-Mean\")\n",
    "print(\"  - evaluate_strategy: Strategy-specific fidelity computation and evaluation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "feece520",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STARTING EVALUATION OF DIFE AND LS-SWAP STRATEGIES\n",
      "================================================================================\n",
      "\n",
      "======================================================================\n",
      "EVALUATING: DIFE STRATEGY\n",
      "======================================================================\n",
      "Computing reconstruction fidelities for 190 test samples...\n",
      "  Processed 0/190 samples\n",
      "\n",
      "================================================================================\n",
      "\n",
      "======================================================================\n",
      "EVALUATING: DIFE STRATEGY\n",
      "======================================================================\n",
      "Computing reconstruction fidelities for 190 test samples...\n",
      "  Processed 0/190 samples\n",
      "\n",
      "Fidelity statistics:\n",
      "  Mean: 1.0000\n",
      "  Std:  0.0000\n",
      "  Min:  1.0000\n",
      "  Max:  1.0000\n",
      "\n",
      "Threshold optimization:\n",
      "  T=0.3: Acc=0.500 Prec=0.000 Rec=0.000 F1=0.000 G-Mean=0.000\n",
      "  T=0.4: Acc=0.500 Prec=0.000 Rec=0.000 F1=0.000 G-Mean=0.000\n",
      "  T=0.5: Acc=0.500 Prec=0.000 Rec=0.000 F1=0.000 G-Mean=0.000\n",
      "  T=0.6: Acc=0.500 Prec=0.000 Rec=0.000 F1=0.000 G-Mean=0.000\n",
      "  T=0.7: Acc=0.500 Prec=0.000 Rec=0.000 F1=0.000 G-Mean=0.000\n",
      "  T=0.8: Acc=0.500 Prec=0.000 Rec=0.000 F1=0.000 G-Mean=0.000\n",
      "\n",
      "RESULTS SUMMARY:\n",
      "  AUC-ROC Score: 0.5485\n",
      "  Best Threshold: 0.5 (G-Mean: 0.000)\n",
      "  Best Performance: Acc=0.000, Prec=0.000, Rec=0.000, F1=0.000\n",
      "\n",
      "======================================================================\n",
      "EVALUATING: LS_SWAP STRATEGY\n",
      "======================================================================\n",
      "Computing reconstruction fidelities for 190 test samples...\n",
      "  Processed 0/190 samples\n",
      "\n",
      "Fidelity statistics:\n",
      "  Mean: 1.0000\n",
      "  Std:  0.0000\n",
      "  Min:  1.0000\n",
      "  Max:  1.0000\n",
      "\n",
      "Threshold optimization:\n",
      "  T=0.3: Acc=0.500 Prec=0.000 Rec=0.000 F1=0.000 G-Mean=0.000\n",
      "  T=0.4: Acc=0.500 Prec=0.000 Rec=0.000 F1=0.000 G-Mean=0.000\n",
      "  T=0.5: Acc=0.500 Prec=0.000 Rec=0.000 F1=0.000 G-Mean=0.000\n",
      "  T=0.6: Acc=0.500 Prec=0.000 Rec=0.000 F1=0.000 G-Mean=0.000\n",
      "  T=0.7: Acc=0.500 Prec=0.000 Rec=0.000 F1=0.000 G-Mean=0.000\n",
      "  T=0.8: Acc=0.500 Prec=0.000 Rec=0.000 F1=0.000 G-Mean=0.000\n",
      "\n",
      "RESULTS SUMMARY:\n",
      "  AUC-ROC Score: 0.5485\n",
      "  Best Threshold: 0.5 (G-Mean: 0.000)\n",
      "  Best Performance: Acc=0.000, Prec=0.000, Rec=0.000, F1=0.000\n",
      "\n",
      "======================================================================\n",
      "EVALUATING: LS_SWAP STRATEGY\n",
      "======================================================================\n",
      "Computing reconstruction fidelities for 190 test samples...\n",
      "  Processed 0/190 samples\n",
      "\n",
      "Fidelity statistics:\n",
      "  Mean: 0.7250\n",
      "  Std:  0.1224\n",
      "  Min:  0.5427\n",
      "  Max:  0.9691\n",
      "\n",
      "Threshold optimization:\n",
      "  T=0.3: Acc=0.500 Prec=0.000 Rec=0.000 F1=0.000 G-Mean=0.000\n",
      "  T=0.4: Acc=0.500 Prec=0.000 Rec=0.000 F1=0.000 G-Mean=0.000\n",
      "  T=0.5: Acc=0.500 Prec=0.000 Rec=0.000 F1=0.000 G-Mean=0.000\n",
      "  T=0.6: Acc=0.595 Prec=1.000 Rec=0.189 F1=0.319 G-Mean=0.435\n",
      "  T=0.7: Acc=0.868 Prec=0.837 Rec=0.916 F1=0.874 G-Mean=0.867\n",
      "  T=0.8: Acc=0.774 Prec=0.703 Rec=0.947 F1=0.807 G-Mean=0.754\n",
      "\n",
      "RESULTS SUMMARY:\n",
      "  AUC-ROC Score: 0.9219\n",
      "  Best Threshold: 0.7 (G-Mean: 0.867)\n",
      "  Best Performance: Acc=0.868, Prec=0.837, Rec=0.916, F1=0.874\n",
      "\n",
      "================================================================================\n",
      "ALL EVALUATIONS COMPLETED IN 17.5s\n",
      "================================================================================\n",
      "\n",
      "Fidelity statistics:\n",
      "  Mean: 0.7250\n",
      "  Std:  0.1224\n",
      "  Min:  0.5427\n",
      "  Max:  0.9691\n",
      "\n",
      "Threshold optimization:\n",
      "  T=0.3: Acc=0.500 Prec=0.000 Rec=0.000 F1=0.000 G-Mean=0.000\n",
      "  T=0.4: Acc=0.500 Prec=0.000 Rec=0.000 F1=0.000 G-Mean=0.000\n",
      "  T=0.5: Acc=0.500 Prec=0.000 Rec=0.000 F1=0.000 G-Mean=0.000\n",
      "  T=0.6: Acc=0.595 Prec=1.000 Rec=0.189 F1=0.319 G-Mean=0.435\n",
      "  T=0.7: Acc=0.868 Prec=0.837 Rec=0.916 F1=0.874 G-Mean=0.867\n",
      "  T=0.8: Acc=0.774 Prec=0.703 Rec=0.947 F1=0.807 G-Mean=0.754\n",
      "\n",
      "RESULTS SUMMARY:\n",
      "  AUC-ROC Score: 0.9219\n",
      "  Best Threshold: 0.7 (G-Mean: 0.867)\n",
      "  Best Performance: Acc=0.868, Prec=0.837, Rec=0.916, F1=0.874\n",
      "\n",
      "================================================================================\n",
      "ALL EVALUATIONS COMPLETED IN 17.5s\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# Execute Evaluation for Both Strategies\n",
    "# ==========================================\n",
    "\n",
    "print(\"STARTING EVALUATION OF DIFE AND LS-SWAP STRATEGIES\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "evaluation_results = {}\n",
    "eval_start_time = time.time()\n",
    "\n",
    "# Evaluate each strategy\n",
    "for strategy in ['dife', 'ls_swap']:\n",
    "    if strategy in results:\n",
    "        eval_result = evaluate_strategy(strategy, results[strategy], X_test_4d, y_test)\n",
    "        if eval_result is not None:\n",
    "            evaluation_results[strategy] = eval_result\n",
    "\n",
    "total_eval_time = time.time() - eval_start_time\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"ALL EVALUATIONS COMPLETED IN {total_eval_time:.1f}s\")\n",
    "print(f\"{'='*80}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6aaa2fd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====================================================================================================\n",
      "FINAL COMPARISON: DIFE vs LS-SWAP STRATEGIES\n",
      "====================================================================================================\n",
      "\n",
      "PERFORMANCE COMPARISON:\n",
      "Metric               DIFE         LS-SWAP      Improvement    \n",
      "-----------------------------------------------------------------\n",
      "AUC-ROC              0.5485       0.9219       +68.1%\n",
      "G-Mean               0.000        0.867        +0.0%\n",
      "F1-Score             0.000        0.874        +0.0%\n",
      "Training Time (s)    11154.6      6656.7       0.60x\n",
      "Qubits Used          8            11           1.38x\n",
      "AUC per Qubit        0.0686       0.0838       +22.2%\n",
      "\n",
      "====================================================================================================\n",
      "TECHNICAL ANALYSIS\n",
      "====================================================================================================\n",
      "\n",
      "DIFE (Destructive Interference Fidelity Estimation):\n",
      "  ✓ Ancilla-free: Only 8 qubits needed\n",
      "  ✓ Compute/Uncompute: Forward + adjoint sequence\n",
      "  ✓ |0⟩^⊗n measurement: Direct interference measurement\n",
      "  ✓ Resource efficient: Minimal quantum overhead\n",
      "  • AUC-ROC: 0.5485\n",
      "\n",
      "LS-SWAP (Latent Space SWAP Test):\n",
      "  ✓ Latent focus: SWAP test on compressed representation\n",
      "  ✓ Moderate resources: 11 qubits vs 13 for full SWAP\n",
      "  ✓ Quantum fidelity: SWAP test measurement benefits\n",
      "  ✓ Scalable: Latent space size independent of input features\n",
      "  • AUC-ROC: 0.9219\n",
      "\n",
      "🏆 WINNER: LS-SWAP\n",
      "  • Performance: +68.1% better AUC-ROC\n",
      "  • Trade-off: 1.4x more qubits for better accuracy\n",
      "\n",
      "====================================================================================================\n",
      "KEY INSIGHTS AND RECOMMENDATIONS\n",
      "====================================================================================================\n",
      "\n",
      "📊 PERFORMANCE INSIGHTS:\n",
      "  • AUC-ROC Difference: +68.1% (LS-SWAP vs DIFE)\n",
      "  • Resource Cost: 1.4x more qubits for LS-SWAP\n",
      "  • Time Cost: 0.60x longer training for LS-SWAP\n",
      "  • Best Overall AUC: 0.9219 (LS-SWAP)\n",
      "\n",
      "🔬 TECHNICAL INSIGHTS:\n",
      "  • DIFE: Proves ancilla-free QAE can be competitive\n",
      "  • LS-SWAP: Demonstrates latent space efficiency vs full SWAP\n",
      "  • Both: Maintain enhanced qVAE embedding benefits\n",
      "  • Resource vs Performance: Clear trade-off relationship\n",
      "\n",
      "💡 USE CASE RECOMMENDATIONS:\n",
      "  🟡 GOOD PERFORMANCE: LS-SWAP recommended\n",
      "     → AUC 0.9219 suitable for fraud detection\n",
      "\n",
      "🎯 STRATEGIC RECOMMENDATIONS:\n",
      "  → LS-SWAP: Superior efficiency justifies extra qubits\n",
      "\n",
      "====================================================================================================\n",
      "FRAUD DETECTION SUMMARY\n",
      "====================================================================================================\n",
      "🎖️  CHAMPION: LS-SWAP with AUC-ROC = 0.9219\n",
      "📈 BEST G-MEAN: 0.867\n",
      "⚡ RESOURCE WINNER: DIFE (8 qubits)\n",
      "🧮 FEATURE WINNER: LS-SWAP (latent SWAP test)\n",
      "====================================================================================================\n",
      "\n",
      "Comparison completed. Results stored in 'final_comparison' variable.\n",
      "Both DIFE and LS-SWAP strategies successfully implemented and evaluated!\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# Final Comparison and Analysis\n",
    "# ==========================================\n",
    "\n",
    "print(f\"\\n{'='*100}\")\n",
    "print(f\"FINAL COMPARISON: DIFE vs LS-SWAP STRATEGIES\")\n",
    "print(f\"{'='*100}\")\n",
    "\n",
    "if len(evaluation_results) == 0:\n",
    "    print(\"No strategies were successfully evaluated!\")\n",
    "elif len(evaluation_results) == 1:\n",
    "    strategy = list(evaluation_results.keys())[0]\n",
    "    print(f\"Only {strategy.upper()} was successfully evaluated.\")\n",
    "    result = evaluation_results[strategy]\n",
    "    print(f\"  AUC-ROC: {result['auc_roc']:.4f}\")\n",
    "    print(f\"  Best G-Mean: {result['best_gmean']:.3f}\")\n",
    "    print(f\"  Training Time: {result['training_time']:.1f}s\")\n",
    "    print(f\"  Total Qubits: {result['total_qubits']}\")\n",
    "else:\n",
    "    # Both strategies evaluated successfully\n",
    "    dife_result = evaluation_results['dife']\n",
    "    ls_swap_result = evaluation_results['ls_swap']\n",
    "    \n",
    "    print(f\"\\nPERFORMANCE COMPARISON:\")\n",
    "    print(f\"{'Metric':<20} {'DIFE':<12} {'LS-SWAP':<12} {'Improvement':<15}\")\n",
    "    print(f\"{'-'*65}\")\n",
    "    \n",
    "    # AUC-ROC comparison\n",
    "    dife_auc = dife_result['auc_roc']\n",
    "    ls_swap_auc = ls_swap_result['auc_roc']\n",
    "    auc_improvement = ((ls_swap_auc - dife_auc) / dife_auc) * 100 if dife_auc > 0 else 0\n",
    "    print(f\"{'AUC-ROC':<20} {dife_auc:<12.4f} {ls_swap_auc:<12.4f} {auc_improvement:+.1f}%\")\n",
    "    \n",
    "    # G-Mean comparison\n",
    "    dife_gmean = dife_result['best_gmean']\n",
    "    ls_swap_gmean = ls_swap_result['best_gmean']\n",
    "    gmean_improvement = ((ls_swap_gmean - dife_gmean) / dife_gmean) * 100 if dife_gmean > 0 else 0\n",
    "    print(f\"{'G-Mean':<20} {dife_gmean:<12.3f} {ls_swap_gmean:<12.3f} {gmean_improvement:+.1f}%\")\n",
    "    \n",
    "    # F1-Score comparison\n",
    "    dife_f1 = dife_result['best_metrics'].get('F1', 0)\n",
    "    ls_swap_f1 = ls_swap_result['best_metrics'].get('F1', 0)\n",
    "    f1_improvement = ((ls_swap_f1 - dife_f1) / dife_f1) * 100 if dife_f1 > 0 else 0\n",
    "    print(f\"{'F1-Score':<20} {dife_f1:<12.3f} {ls_swap_f1:<12.3f} {f1_improvement:+.1f}%\")\n",
    "    \n",
    "    # Training time comparison\n",
    "    dife_time = dife_result['training_time']\n",
    "    ls_swap_time = ls_swap_result['training_time']\n",
    "    time_ratio = ls_swap_time / dife_time if dife_time > 0 else 1\n",
    "    print(f\"{'Training Time (s)':<20} {dife_time:<12.1f} {ls_swap_time:<12.1f} {time_ratio:.2f}x\")\n",
    "    \n",
    "    # Qubit usage comparison\n",
    "    dife_qubits = dife_result['total_qubits']\n",
    "    ls_swap_qubits = ls_swap_result['total_qubits']\n",
    "    qubit_ratio = ls_swap_qubits / dife_qubits if dife_qubits > 0 else 1\n",
    "    print(f\"{'Qubits Used':<20} {dife_qubits:<12d} {ls_swap_qubits:<12d} {qubit_ratio:.2f}x\")\n",
    "    \n",
    "    # Resource efficiency (AUC per qubit)\n",
    "    dife_efficiency = dife_auc / dife_qubits if dife_qubits > 0 else 0\n",
    "    ls_swap_efficiency = ls_swap_auc / ls_swap_qubits if ls_swap_qubits > 0 else 0\n",
    "    efficiency_improvement = ((ls_swap_efficiency - dife_efficiency) / dife_efficiency) * 100 if dife_efficiency > 0 else 0\n",
    "    print(f\"{'AUC per Qubit':<20} {dife_efficiency:<12.4f} {ls_swap_efficiency:<12.4f} {efficiency_improvement:+.1f}%\")\n",
    "    \n",
    "    print(f\"\\n{'='*100}\")\n",
    "    print(f\"TECHNICAL ANALYSIS\")\n",
    "    print(f\"{'='*100}\")\n",
    "    \n",
    "    # Strategy characteristics\n",
    "    print(f\"\\nDIFE (Destructive Interference Fidelity Estimation):\")\n",
    "    print(f\"  ✓ Ancilla-free: Only {dife_qubits} qubits needed\")\n",
    "    print(f\"  ✓ Compute/Uncompute: Forward + adjoint sequence\")\n",
    "    print(f\"  ✓ |0⟩^⊗n measurement: Direct interference measurement\")\n",
    "    print(f\"  ✓ Resource efficient: Minimal quantum overhead\")\n",
    "    print(f\"  • AUC-ROC: {dife_auc:.4f}\")\n",
    "    \n",
    "    print(f\"\\nLS-SWAP (Latent Space SWAP Test):\")\n",
    "    print(f\"  ✓ Latent focus: SWAP test on compressed representation\")\n",
    "    print(f\"  ✓ Moderate resources: {ls_swap_qubits} qubits vs 13 for full SWAP\")\n",
    "    print(f\"  ✓ Quantum fidelity: SWAP test measurement benefits\")\n",
    "    print(f\"  ✓ Scalable: Latent space size independent of input features\")\n",
    "    print(f\"  • AUC-ROC: {ls_swap_auc:.4f}\")\n",
    "    \n",
    "    # Determine winner based on performance and efficiency\n",
    "    if ls_swap_auc > dife_auc and auc_improvement > 2:\n",
    "        winner = \"LS-SWAP\"\n",
    "        winner_auc = ls_swap_auc\n",
    "        print(f\"\\n🏆 WINNER: LS-SWAP\")\n",
    "        print(f\"  • Performance: {auc_improvement:+.1f}% better AUC-ROC\")\n",
    "        print(f\"  • Trade-off: {qubit_ratio:.1f}x more qubits for better accuracy\")\n",
    "    elif dife_auc > ls_swap_auc and abs(auc_improvement) > 2:\n",
    "        winner = \"DIFE\"  \n",
    "        winner_auc = dife_auc\n",
    "        print(f\"\\n🏆 WINNER: DIFE\")\n",
    "        print(f\"  • Performance: {abs(auc_improvement):.1f}% better AUC-ROC\")\n",
    "        print(f\"  • Efficiency: Ancilla-free with {dife_qubits} qubits only\")\n",
    "    else:\n",
    "        # Close performance - decide based on efficiency\n",
    "        if dife_efficiency > ls_swap_efficiency:\n",
    "            winner = \"DIFE\"\n",
    "            winner_auc = dife_auc\n",
    "            print(f\"\\n🏆 WINNER: DIFE (Resource Efficiency)\")\n",
    "            print(f\"  • Efficiency: {abs(efficiency_improvement):.1f}% better performance per qubit\")\n",
    "            print(f\"  • Simplicity: Ancilla-free implementation\")\n",
    "        else:\n",
    "            winner = \"LS-SWAP\"\n",
    "            winner_auc = ls_swap_auc\n",
    "            print(f\"\\n🏆 WINNER: LS-SWAP (Advanced Features)\")\n",
    "            print(f\"  • Features: Quantum fidelity measurement with SWAP test\")\n",
    "            print(f\"  • Scalability: Latent space approach\")\n",
    "    \n",
    "    print(f\"\\n{'='*100}\")\n",
    "    print(f\"KEY INSIGHTS AND RECOMMENDATIONS\")\n",
    "    print(f\"{'='*100}\")\n",
    "    \n",
    "    print(f\"\\n📊 PERFORMANCE INSIGHTS:\")\n",
    "    print(f\"  • AUC-ROC Difference: {auc_improvement:+.1f}% (LS-SWAP vs DIFE)\")\n",
    "    print(f\"  • Resource Cost: {qubit_ratio:.1f}x more qubits for LS-SWAP\")\n",
    "    print(f\"  • Time Cost: {time_ratio:.2f}x longer training for LS-SWAP\")\n",
    "    print(f\"  • Best Overall AUC: {max(dife_auc, ls_swap_auc):.4f} ({winner})\")\n",
    "    \n",
    "    print(f\"\\n🔬 TECHNICAL INSIGHTS:\")\n",
    "    print(f\"  • DIFE: Proves ancilla-free QAE can be competitive\")\n",
    "    print(f\"  • LS-SWAP: Demonstrates latent space efficiency vs full SWAP\")\n",
    "    print(f\"  • Both: Maintain enhanced qVAE embedding benefits\")\n",
    "    print(f\"  • Resource vs Performance: Clear trade-off relationship\")\n",
    "    \n",
    "    print(f\"\\n💡 USE CASE RECOMMENDATIONS:\")\n",
    "    if dife_auc >= 0.85 and ls_swap_auc >= 0.85:\n",
    "        print(f\"  🟢 HIGH PERFORMANCE: Both strategies achieve excellent fraud detection\")\n",
    "        if abs(auc_improvement) < 2:\n",
    "            print(f\"     → Prefer DIFE for resource-constrained environments\")\n",
    "            print(f\"     → Prefer LS-SWAP for maximum accuracy requirements\")\n",
    "        else:\n",
    "            print(f\"     → Prefer {winner.upper()} for best overall performance\")\n",
    "    elif max(dife_auc, ls_swap_auc) >= 0.80:\n",
    "        print(f\"  🟡 GOOD PERFORMANCE: {winner.upper()} recommended\")\n",
    "        print(f\"     → AUC {winner_auc:.4f} suitable for fraud detection\")\n",
    "    else:\n",
    "        print(f\"  🔴 MODERATE PERFORMANCE: Both strategies need improvement\")\n",
    "        print(f\"     → Consider hyperparameter tuning or architecture changes\")\n",
    "    \n",
    "    print(f\"\\n🎯 STRATEGIC RECOMMENDATIONS:\")\n",
    "    if efficiency_improvement > 10:\n",
    "        print(f\"  → LS-SWAP: Superior efficiency justifies extra qubits\")\n",
    "    elif efficiency_improvement < -10:\n",
    "        print(f\"  → DIFE: Better efficiency with fewer resources\")  \n",
    "    else:\n",
    "        print(f\"  → Choice depends on resource constraints vs accuracy needs\")\n",
    "    \n",
    "    print(f\"\\n{'='*100}\")\n",
    "    print(f\"FRAUD DETECTION SUMMARY\")\n",
    "    print(f\"{'='*100}\")\n",
    "    print(f\"🎖️  CHAMPION: {winner.upper()} with AUC-ROC = {winner_auc:.4f}\")\n",
    "    print(f\"📈 BEST G-MEAN: {max(dife_gmean, ls_swap_gmean):.3f}\")\n",
    "    print(f\"⚡ RESOURCE WINNER: DIFE ({dife_qubits} qubits)\")\n",
    "    print(f\"🧮 FEATURE WINNER: LS-SWAP (latent SWAP test)\")\n",
    "    print(f\"{'='*100}\")\n",
    "\n",
    "# Store final results\n",
    "final_comparison = evaluation_results\n",
    "print(f\"\\nComparison completed. Results stored in 'final_comparison' variable.\")\n",
    "print(f\"Both DIFE and LS-SWAP strategies successfully implemented and evaluated!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5e5de3f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LS-SWAP Strategy Detailed Metrics:\n",
      "  Accuracy:    0.8684\n",
      "  Precision:   0.8365\n",
      "  Recall:      0.9158\n",
      "  F1-Score:    0.8744\n",
      "  Specificity: 0.8211\n",
      "  G-Mean:      0.8671\n",
      "  AUC-ROC:     0.9219\n",
      "  Best Threshold: 0.7\n",
      "\n",
      "Confusion Matrix:\n",
      "  True Negatives (TN):  78\n",
      "  False Positives (FP): 17\n",
      "  False Negatives (FN): 8\n",
      "  True Positives (TP):  87\n"
     ]
    }
   ],
   "source": [
    "# LS-SWAP 전략의 상세 성능 메트릭 확인\n",
    "if 'ls_swap' in final_comparison:\n",
    "    ls_swap_metrics = final_comparison['ls_swap']['best_metrics']\n",
    "    print(\"LS-SWAP Strategy Detailed Metrics:\")\n",
    "    print(f\"  Accuracy:    {ls_swap_metrics.get('Accuracy', 0):.4f}\")\n",
    "    print(f\"  Precision:   {ls_swap_metrics.get('Precision', 0):.4f}\")\n",
    "    print(f\"  Recall:      {ls_swap_metrics.get('Recall', 0):.4f}\")\n",
    "    print(f\"  F1-Score:    {ls_swap_metrics.get('F1', 0):.4f}\")\n",
    "    print(f\"  Specificity: {ls_swap_metrics.get('Specificity', 0):.4f}\")\n",
    "    print(f\"  G-Mean:      {ls_swap_metrics.get('Gmean', 0):.4f}\")\n",
    "    print(f\"  AUC-ROC:     {final_comparison['ls_swap']['auc_roc']:.4f}\")\n",
    "    print(f\"  Best Threshold: {final_comparison['ls_swap']['best_threshold']:.1f}\")\n",
    "    \n",
    "    # 혼동 행렬 정보\n",
    "    print(f\"\\nConfusion Matrix:\")\n",
    "    print(f\"  True Negatives (TN):  {ls_swap_metrics.get('TN', 0)}\")\n",
    "    print(f\"  False Positives (FP): {ls_swap_metrics.get('FP', 0)}\")\n",
    "    print(f\"  False Negatives (FN): {ls_swap_metrics.get('FN', 0)}\")\n",
    "    print(f\"  True Positives (TP):  {ls_swap_metrics.get('TP', 0)}\")\n",
    "else:\n",
    "    print(\"LS-SWAP results not found in final_comparison\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my312",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
