{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1345944a",
   "metadata": {},
   "source": [
    "# Credit Card Fraud Detection using Random Forest\n",
    "\n",
    "이 노트북은 신용 카드 사기 탐지를 위한 랜덤 포레스트(Random Forest) 모델을 구현합니다. \n",
    "랜덤 포레스트는 여러 개의 결정 트리(Decision Tree)를 앙상블하는 기법으로, 복잡한 패턴을 학습하고 견고한 예측을 제공합니다.\n",
    "\n",
    "## 랜덤 포레스트 개요\n",
    "\n",
    "랜덤 포레스트는 다음과 같은 주요 특징을 가집니다:\n",
    "\n",
    "1. **결정 트리의 앙상블**: 다수의 결정 트리를 생성하고 그 결과를 결합합니다.\n",
    "2. **배깅(Bootstrap Aggregating)**: 훈련 데이터에서 무작위로 샘플을 추출하여 각 트리를 학습시킵니다.\n",
    "3. **특성 무작위 선택**: 각 노드에서 분할에 사용할 특성의 부분집합을 무작위로 선택합니다.\n",
    "4. **다수결 또는 평균화**: 분류는 다수결로, 회귀는 평균으로 최종 결과를 도출합니다.\n",
    "\n",
    "이러한 특성으로 인해 랜덤 포레스트는 과적합에 강하고 복잡한 패턴을 학습할 수 있어 사기 탐지와 같은 불균형 데이터셋에 효과적입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c25973f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core libraries for data processing and machine learning\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (confusion_matrix, accuracy_score, precision_score,\n",
    "                            recall_score, f1_score, roc_auc_score, roc_curve)\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "# 불필요한 경고 무시\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f2a1eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# Data Loading and Preprocessing Pipeline\n",
    "# ==========================================\n",
    "\n",
    "# Load preprocessed credit card fraud dataset\n",
    "df = pd.read_csv(\"preprocessed-creditcard.csv\")\n",
    "X = df.drop(\"Class\", axis=1).values  # Feature matrix\n",
    "y = df[\"Class\"].values                # Target labels (0: normal, 1: fraud)\n",
    "\n",
    "print(f\"Dataset loaded: {X.shape[0]} samples, {X.shape[1]} features\")\n",
    "print(f\"Fraud rate: {np.mean(y):.4f} ({np.sum(y)} fraud cases)\")\n",
    "\n",
    "# Stratified train-test split to maintain class distribution\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# Feature standardization using Z-score normalization\n",
    "# Note: Random Forest doesn't strictly require feature scaling, but it can help with interpretation\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(f\"\\nTraining set: {X_train.shape}\")\n",
    "print(f\"Test set: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f383ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# Configuration\n",
    "# ==========================================\n",
    "\n",
    "# TRAINING CONFIGURATION\n",
    "TRAINING_CONFIG = {\n",
    "    'n_estimators': 100,          # Number of trees in the forest\n",
    "    'max_depth': 10,              # Maximum depth of the tree\n",
    "    'min_samples_split': 2,       # Minimum samples required to split a node\n",
    "    'min_samples_leaf': 1,        # Minimum samples required at a leaf node\n",
    "    'bootstrap': True,            # Whether bootstrap samples are used\n",
    "    'criterion': 'gini',          # Function to measure quality of a split\n",
    "    'class_weight': 'balanced',   # Weights for classes (useful for imbalanced datasets)\n",
    "    'random_state': 42,           # Seed for reproducibility\n",
    "    'n_jobs': -1                  # Use all available cores\n",
    "}\n",
    "\n",
    "print(f\"\\nTraining Configuration: {TRAINING_CONFIG}\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46fa3c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_random_forest_model(X_train, y_train, config):\n",
    "    \"\"\"\n",
    "    랜덤 포레스트 모델 학습 함수\n",
    "    \n",
    "    Args:\n",
    "        X_train: 훈련 데이터\n",
    "        y_train: 훈련 레이블\n",
    "        config: 모델 설정 파라미터\n",
    "        \n",
    "    Returns:\n",
    "        model: 학습된 랜덤 포레스트 모델\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"TRAINING: RANDOM FOREST MODEL\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # 훈련 시작 시간 기록\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # 모델 생성 및 학습\n",
    "    model = RandomForestClassifier(\n",
    "        n_estimators=config['n_estimators'],\n",
    "        max_depth=config['max_depth'],\n",
    "        min_samples_split=config['min_samples_split'],\n",
    "        min_samples_leaf=config['min_samples_leaf'],\n",
    "        bootstrap=config['bootstrap'],\n",
    "        criterion=config['criterion'],\n",
    "        class_weight=config['class_weight'],\n",
    "        random_state=config['random_state'],\n",
    "        n_jobs=config['n_jobs'],\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # 훈련 종료 시간과 소요 시간 계산\n",
    "    training_time = time.time() - start_time\n",
    "    print(f\"\\nTraining completed in {training_time:.2f} seconds\")\n",
    "    \n",
    "    return {\n",
    "        'model': model,\n",
    "        'training_time': training_time\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f3bcad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 학습\n",
    "results = {}\n",
    "try:\n",
    "    rf_result = train_random_forest_model(X_train, y_train, TRAINING_CONFIG)\n",
    "    results['rf'] = rf_result\n",
    "    print(f\"✓ Random Forest model completed successfully\")\n",
    "except Exception as e:\n",
    "    print(f\"✗ Random Forest model failed: {str(e)}\")\n",
    "    results['rf'] = {'error': str(e)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb9341ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 특성 중요도 시각화\n",
    "def plot_feature_importance(model, feature_names, top_n=15):\n",
    "    \"\"\"\n",
    "    랜덤 포레스트 모델의 특성 중요도를 시각화하는 함수\n",
    "    \n",
    "    Args:\n",
    "        model: 학습된 랜덤 포레스트 모델\n",
    "        feature_names: 특성 이름 리스트\n",
    "        top_n: 표시할 상위 특성 수\n",
    "    \"\"\"\n",
    "    # 특성 중요도 추출\n",
    "    importances = model.feature_importances_\n",
    "    indices = np.argsort(importances)[::-1]\n",
    "    \n",
    "    # 상위 N개 특성만 선택\n",
    "    top_indices = indices[:top_n]\n",
    "    top_importances = importances[top_indices]\n",
    "    top_feature_names = [feature_names[i] for i in top_indices]\n",
    "    \n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.title('Feature Importances')\n",
    "    plt.barh(range(len(top_indices)), top_importances, align='center')\n",
    "    plt.yticks(range(len(top_indices)), top_feature_names)\n",
    "    plt.xlabel('Relative Importance')\n",
    "    plt.gca().invert_yaxis()  # 중요도가 높은 항목을 위쪽에 표시\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "# 특성 중요도 시각화 (학습이 성공적으로 완료된 경우)\n",
    "if 'error' not in results['rf']:\n",
    "    # 특성 이름이 없는 경우 번호로 대체\n",
    "    feature_names = [f\"Feature_{i}\" for i in range(X_train.shape[1])]\n",
    "    plot_feature_importance(results['rf']['model'], feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89cbeb67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 평가\n",
    "def evaluate_model(model, X_test, y_test):\n",
    "    \"\"\"\n",
    "    학습된 랜덤 포레스트 모델 평가 함수\n",
    "    \n",
    "    Args:\n",
    "        model: 학습된 랜덤 포레스트 모델\n",
    "        X_test: 테스트 데이터\n",
    "        y_test: 테스트 레이블\n",
    "        \n",
    "    Returns:\n",
    "        dict: 평가 지표들을 포함한 딕셔너리\n",
    "    \"\"\"\n",
    "    # 예측 확률 계산\n",
    "    y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    # 다양한 임계값에서의 성능 평가\n",
    "    thresholds = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "    results = []\n",
    "    \n",
    "    print(\"Threshold optimization:\")\n",
    "    for threshold in thresholds:\n",
    "        y_pred = (y_pred_proba >= threshold).astype(int)\n",
    "        \n",
    "        # 혼동 행렬 계산\n",
    "        tn, fp, fn, tp = confusion_matrix(y_test, y_pred, labels=[0,1]).ravel()\n",
    "        \n",
    "        # 평가 지표 계산\n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        prec = precision_score(y_test, y_pred, zero_division=0)\n",
    "        rec = recall_score(y_test, y_pred, zero_division=0)\n",
    "        f1 = f1_score(y_test, y_pred, zero_division=0)\n",
    "        spec = tn / (tn + fp) if (tn + fp) else 0.0\n",
    "        gmean = (rec * spec) ** 0.5\n",
    "        \n",
    "        results.append({\n",
    "            'threshold': threshold,\n",
    "            'accuracy': acc,\n",
    "            'precision': prec,\n",
    "            'recall': rec,\n",
    "            'f1_score': f1,\n",
    "            'specificity': spec,\n",
    "            'gmean': gmean,\n",
    "            'confusion_matrix': {\n",
    "                'tn': int(tn),\n",
    "                'fp': int(fp),\n",
    "                'fn': int(fn),\n",
    "                'tp': int(tp)\n",
    "            }\n",
    "        })\n",
    "        \n",
    "        print(f\"  T={threshold:.1f}: Acc={acc:.3f} Prec={prec:.3f} Rec={rec:.3f} \"\n",
    "              f\"F1={f1:.3f} G-Mean={gmean:.3f}\")\n",
    "    \n",
    "    # AUC-ROC 점수 계산\n",
    "    auc = roc_auc_score(y_test, y_pred_proba)\n",
    "    \n",
    "    # G-Mean 기준으로 최적의 임계값 찾기\n",
    "    best_result = max(results, key=lambda x: x['gmean'])\n",
    "    \n",
    "    print(\"\\nRESULTS SUMMARY:\")\n",
    "    print(f\"  AUC-ROC Score: {auc:.4f}\")\n",
    "    print(f\"  Best Threshold: {best_result['threshold']:.1f} (G-Mean: {best_result['gmean']:.3f})\")\n",
    "    print(f\"  Best Performance: Acc={best_result['accuracy']:.3f}, \"\n",
    "          f\"Prec={best_result['precision']:.3f}, Rec={best_result['recall']:.3f}, \"\n",
    "          f\"F1={best_result['f1_score']:.3f}\")\n",
    "    \n",
    "    # 최적의 임계값에서의 혼동 행렬\n",
    "    cm = best_result['confusion_matrix']\n",
    "    print(f\"\\nConfusion Matrix at threshold={best_result['threshold']:.1f}:\")\n",
    "    print(f\"  True Negative: {cm['tn']}, False Positive: {cm['fp']}\")\n",
    "    print(f\"  False Negative: {cm['fn']}, True Positive: {cm['tp']}\")\n",
    "    \n",
    "    return {\n",
    "        'auc': auc,\n",
    "        'best_threshold': best_result['threshold'],\n",
    "        'best_metrics': best_result,\n",
    "        'all_results': results\n",
    "    }\n",
    "\n",
    "# 모델 평가 (학습이 성공적으로 완료된 경우)\n",
    "if 'error' not in results['rf']:\n",
    "    eval_results = evaluate_model(results['rf']['model'], X_test, y_test)\n",
    "    results['rf']['evaluation'] = eval_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1148153",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC 곡선 시각화\n",
    "def plot_roc_curve(y_test, y_scores, title=\"ROC Curve\"):\n",
    "    \"\"\"\n",
    "    ROC 곡선을 시각화하는 함수\n",
    "    \n",
    "    Args:\n",
    "        y_test: 실제 레이블\n",
    "        y_scores: 예측 확률 또는 점수\n",
    "        title: 그래프 제목\n",
    "    \"\"\"\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, y_scores)\n",
    "    roc_auc = roc_auc_score(y_test, y_scores)\n",
    "    \n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.plot(fpr, tpr, color='darkorange', lw=2, \n",
    "             label=f'ROC curve (area = {roc_auc:.3f})')\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title(title)\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "# 혼동 행렬 시각화\n",
    "def plot_confusion_matrix(y_true, y_pred, labels=None, title=\"Confusion Matrix\"):\n",
    "    \"\"\"\n",
    "    혼동 행렬을 시각화하는 함수\n",
    "    \n",
    "    Args:\n",
    "        y_true: 실제 레이블\n",
    "        y_pred: 예측 레이블\n",
    "        labels: 레이블 이름 리스트\n",
    "        title: 그래프 제목\n",
    "    \"\"\"\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                xticklabels=labels if labels else ['Normal', 'Fraud'],\n",
    "                yticklabels=labels if labels else ['Normal', 'Fraud'])\n",
    "    plt.title(title)\n",
    "    plt.ylabel('Actual')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# ROC 곡선과 최적 임계값에서의 혼동 행렬 시각화\n",
    "if 'error' not in results['rf'] and 'evaluation' in results['rf']:\n",
    "    # ROC 곡선\n",
    "    y_scores = results['rf']['model'].predict_proba(X_test)[:, 1]\n",
    "    plot_roc_curve(y_test, y_scores, title='Random Forest ROC Curve')\n",
    "    \n",
    "    # 최적 임계값에서의 혼동 행렬\n",
    "    best_threshold = results['rf']['evaluation']['best_threshold']\n",
    "    y_pred = (y_scores >= best_threshold).astype(int)\n",
    "    plot_confusion_matrix(y_test, y_pred, title=f\"Confusion Matrix (Threshold={best_threshold:.1f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c99d9dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 하이퍼파라미터 튜닝 (선택 사항)\n",
    "def tune_hyperparameters(X_train, y_train, verbose=True):\n",
    "    \"\"\"\n",
    "    랜덤 포레스트 모델의 하이퍼파라미터를 최적화하는 함수\n",
    "    \n",
    "    Args:\n",
    "        X_train: 훈련 데이터\n",
    "        y_train: 훈련 레이블\n",
    "        verbose: 상세 출력 여부\n",
    "        \n",
    "    Returns:\n",
    "        dict: 최적의 파라미터와 모델을 포함한 딕셔너리\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"HYPERPARAMETER TUNING\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # 튜닝 시작 시간 기록\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # 탐색할 파라미터 그리드\n",
    "    param_grid = {\n",
    "        'n_estimators': [50, 100, 200],\n",
    "        'max_depth': [5, 10, 15, None],\n",
    "        'min_samples_split': [2, 5, 10],\n",
    "        'class_weight': ['balanced', 'balanced_subsample', None]\n",
    "    }\n",
    "    \n",
    "    # 기본 모델 생성\n",
    "    base_model = RandomForestClassifier(\n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "        verbose=0\n",
    "    )\n",
    "    \n",
    "    # Grid Search 설정\n",
    "    grid_search = GridSearchCV(\n",
    "        estimator=base_model,\n",
    "        param_grid=param_grid,\n",
    "        cv=3,                    # 3-fold cross-validation\n",
    "        scoring='f1',            # F1 score for imbalanced classification\n",
    "        n_jobs=-1,               # Use all available cores\n",
    "        verbose=int(verbose)\n",
    "    )\n",
    "    \n",
    "    # Grid Search 실행\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    # 튜닝 종료 시간과 소요 시간 계산\n",
    "    tuning_time = time.time() - start_time\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"\\nTuning completed in {tuning_time:.2f} seconds\")\n",
    "        print(f\"Best parameters: {grid_search.best_params_}\")\n",
    "        print(f\"Best cross-validation score: {grid_search.best_score_:.3f}\")\n",
    "    \n",
    "    return {\n",
    "        'best_params': grid_search.best_params_,\n",
    "        'best_score': grid_search.best_score_,\n",
    "        'best_model': grid_search.best_estimator_,\n",
    "        'tuning_time': tuning_time\n",
    "    }\n",
    "\n",
    "# 하이퍼파라미터 튜닝은 시간이 많이 소요되므로 기본적으로 비활성화됨\n",
    "# 활성화하려면 아래 주석을 해제하세요\n",
    "\"\"\"\n",
    "try:\n",
    "    tuning_results = tune_hyperparameters(X_train, y_train)\n",
    "    results['tuning'] = tuning_results\n",
    "    \n",
    "    # 튜닝된 모델 평가\n",
    "    tuned_model = tuning_results['best_model']\n",
    "    tuned_eval = evaluate_model(tuned_model, X_test, y_test)\n",
    "    results['tuned_rf'] = {\n",
    "        'model': tuned_model,\n",
    "        'evaluation': tuned_eval\n",
    "    }\n",
    "    \n",
    "    print(f\"✓ Hyperparameter tuning completed successfully\")\n",
    "except Exception as e:\n",
    "    print(f\"✗ Hyperparameter tuning failed: {str(e)}\")\n",
    "    results['tuning'] = {'error': str(e)}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c89ec6a4",
   "metadata": {},
   "source": [
    "## 랜덤 포레스트 모델 분석 및 결론\n",
    "\n",
    "랜덤 포레스트를 사용한 신용 카드 사기 탐지의 결과를 분석합니다:\n",
    "\n",
    "1. **모델 성능 분석**:\n",
    "   - AUC-ROC 점수와 최적의 임계값\n",
    "   - 정확도, 정밀도, 재현율, F1 점수, G-Mean 등 다양한 성능 지표\n",
    "   - 혼동 행렬 분석\n",
    "\n",
    "2. **특성 중요도 분석**:\n",
    "   - 어떤 거래 특성이 사기 탐지에 가장 중요한지 파악\n",
    "   - 비즈니스 인사이트 도출\n",
    "\n",
    "3. **장단점 분석**:\n",
    "   - 랜덤 포레스트의 강점: 견고성, 정확성, 특성 중요도 제공\n",
    "   - 단점: 해석 가능성 부족, 계산 비용\n",
    "   - 다른 모델(Classical AE, CNN 등)과의 비교\n",
    "\n",
    "4. **결론 및 향후 연구 방향**:\n",
    "   - 랜덤 포레스트가 어떤 종류의 사기 패턴을 더 잘 탐지하는가\n",
    "   - 개선할 수 있는 부분과 향후 연구 방향"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my312",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
